{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "# we define all the configuration here\n",
        "import pickle\n",
        "\n",
        "with open('multi_class_dict_746.pkl', 'rb') as f:\n",
        "    loaded_dict = pickle.load(f)\n",
        "\n",
        "NB_FAMILIES = 736\n",
        "MAX_LEN = 100\n",
        "TRAIN_BATCH_SIZE = 256 #16\n",
        "VALID_BATCH_SIZE = 128 #8\n",
        "EPOCHS = 10\n",
        "CHAR_INDEX_DICT = {'a': 0,\n",
        " 'b': 1,\n",
        " 'c': 2,\n",
        " 'd': 3,\n",
        " 'e': 4,\n",
        " 'f': 5,\n",
        " 'g': 6,\n",
        " 'h': 7,\n",
        " 'i': 8,\n",
        " 'k': 9,\n",
        " 'l': 10,\n",
        " 'm': 11,\n",
        " 'n': 12,\n",
        " 'o': 13,\n",
        " 'p': 14,\n",
        " 'q': 15,\n",
        " 'r': 16,\n",
        " 's': 17,\n",
        " 't': 18,\n",
        " 'u': 19,\n",
        " 'v': 20,\n",
        " 'w': 21,\n",
        " 'x': 22,\n",
        " 'y': 23,\n",
        " 'z': 24}\n",
        "MULTI_CLASS_DICT = loaded_dict"
      ],
      "metadata": {
        "id": "Ba6RAOCO_YkE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.py\n",
        "import torch\n",
        "class PFAMDataset:\n",
        "    def __init__(self, reviews, targets):\n",
        "         \"\"\"\n",
        "         :param reviews: this is a numpy array\n",
        "         :param targets: a vector, numpy array\n",
        "         \"\"\"\n",
        "         self.reviews = reviews\n",
        "         self.target = targets\n",
        "    def __len__(self):\n",
        "        # returns length of the dataset\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "         # for any given item, which is an int,\n",
        "         # return review and targets as torch tensor\n",
        "         # item is the index of the item in concern\n",
        "         review = self.reviews[item, :]\n",
        "         target = self.target[item]\n",
        "         return {\"review\": torch.tensor(review, dtype=torch.long),\n",
        "                 \"target\": torch.tensor(target, dtype=torch.float) }"
      ],
      "metadata": {
        "id": "dbOcaEyU_dzI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# engine.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def train(data_loader, model, optimizer, device):\n",
        "     \"\"\"\n",
        "    This is the main training function that trains model\n",
        "     for one epoch\n",
        "     :param data_loader: this is the torch dataloader\n",
        "     :param model: model (lstm model)\n",
        "     :param optimizer: torch optimizer, e.g. adam, sgd, etc.\n",
        "     :param device: this can be \"cuda\" or \"cpu\"\n",
        "     \"\"\"\n",
        "\n",
        "     # set model to training mode\n",
        "     model.train()\n",
        "     # go through batches of data in data loader\n",
        "     for data in data_loader:\n",
        "         # fetch review and target from the dict\n",
        "         reviews = data[\"review\"]\n",
        "         targets = data[\"target\"]\n",
        "         # move the data to device that we want to use\n",
        "         reviews = reviews.to(device, dtype=torch.long)\n",
        "         targets = targets.to(device, dtype=torch.float)\n",
        "         # clear the gradients\n",
        "         optimizer.zero_grad()\n",
        "         # make predictions from the model\n",
        "         predictions = model(reviews)\n",
        "         # calculate the loss\n",
        "         loss = nn.CrossEntropyLoss()(\n",
        "         predictions,\n",
        "         targets.view(-1, 1)\n",
        "         )\n",
        "         # compute gradient of loss w.r.t.\n",
        "         # all parameters of the model that are trainable\n",
        "         loss.backward()\n",
        "         # single optimization step\n",
        "         optimizer.step()\n",
        "\n",
        "def evaluate(data_loader, model, device):\n",
        "     # initialize empty lists to store predictions\n",
        "     # and targets\n",
        "     final_predictions = []\n",
        "     final_targets = []\n",
        "     # put the model in eval mode\n",
        "     model.eval()\n",
        "     # disable gradient calculation\n",
        "     with torch.no_grad():\n",
        "         for data in data_loader:\n",
        "             reviews = data[\"review\"]\n",
        "             targets = data[\"target\"]\n",
        "             reviews = reviews.to(device, dtype=torch.long)\n",
        "             targets = targets.to(device, dtype=torch.float)\n",
        "             # make predictions\n",
        "             predictions = model(reviews)\n",
        "             # move predictions and targets to list\n",
        "             # we need to move predictions and targets to cpu too\n",
        "             predictions = predictions.cpu().numpy().tolist()\n",
        "             targets = data[\"target\"].cpu().numpy().tolist()\n",
        "             final_predictions.extend(predictions)\n",
        "             final_targets.extend(targets)\n",
        "     # return final predictions and targets\n",
        "     return final_predictions, final_targets"
      ],
      "metadata": {
        "id": "6a7vi4Lp_huU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "         \"\"\"\n",
        "         :param embedding_matrix: numpy array with vectors for all words\n",
        "         \"\"\"\n",
        "         super(LSTM, self).__init__()\n",
        "         # number of words = number of rows in embedding matrix\n",
        "         num_words = embedding_matrix.shape[0]\n",
        "         # dimension of embedding is num of columns in the matrix\n",
        "         embed_dim = embedding_matrix.shape[1]\n",
        "         # we define an input embedding layer\n",
        "         self.embedding = nn.Embedding(\n",
        "         num_embeddings=num_words,\n",
        "         embedding_dim=embed_dim\n",
        "         )\n",
        "         # embedding matrix is used as weights of\n",
        "         # the embedding layer\n",
        "         self.embedding.weight = nn.Parameter(\n",
        "         torch.tensor(\n",
        "         embedding_matrix,\n",
        "         dtype=torch.float32\n",
        "         )\n",
        "         )\n",
        "         # we dont want to train the pretrained embeddings\n",
        "         self.embedding.weight.requires_grad = False\n",
        "         # a simple bidirectional LSTM with\n",
        "         # hidden size of 128\n",
        "         self.lstm = nn.LSTM(\n",
        "             embed_dim,\n",
        "             128,\n",
        "             bidirectional=True,\n",
        "             batch_first=True,\n",
        "         )\n",
        "         # output layer which is a linear layer\n",
        "         # we have only one output\n",
        "         # input (512) = 128 + 128 for mean and same for max pooling\n",
        "         self.out = nn.Linear(512, NB_FAMILIES)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "         # pass data through embedding layer\n",
        "         # the input is just the tokens\n",
        "         x = self.embedding(x)\n",
        "         # move embedding output to lstm\n",
        "         x, _ = self.lstm(x)\n",
        "         # apply mean and max pooling on lstm output\n",
        "         avg_pool = torch.mean(x, 1)\n",
        "         max_pool, _ = torch.max(x, 1)\n",
        "\n",
        "         # concatenate mean and max pooling\n",
        "         # this is why size is 512\n",
        "         # 128 for each direction = 256\n",
        "         # avg_pool = 256 and max_pool = 256\n",
        "         out = torch.cat((avg_pool, max_pool), 1)\n",
        "         # pass through the output layer and return the output\n",
        "         out = self.out(out)\n",
        "         # return linear output\n",
        "         return out"
      ],
      "metadata": {
        "id": "nc3ejx-k_l1h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicConvResBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=128, n_filters=256, kernel_size=3, padding=1, stride=1, shortcut=False, downsample=None):\n",
        "        super(BasicConvResBlock, self).__init__()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.shortcut = shortcut\n",
        "\n",
        "        self.conv1 = nn.Conv1d(input_dim, n_filters, kernel_size=kernel_size, padding=padding, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm1d(n_filters)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(n_filters, n_filters, kernel_size=kernel_size, padding=padding, stride=stride)\n",
        "        self.bn2 = nn.BatchNorm1d(n_filters)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.shortcut:\n",
        "            if self.downsample is not None:\n",
        "                residual = self.downsample(x)\n",
        "            out += residual\n",
        "\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class VDCNN(nn.Module):\n",
        "\n",
        "    def __init__(self,embedding_matrix):\n",
        "        super(VDCNN, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        fc_layers = []\n",
        "        # number of words = number of rows in embedding matrix\n",
        "        num_embedding = embedding_matrix.shape[0]\n",
        "        # dimension of embedding is num of columns in the matrix\n",
        "        embedding_dim = embedding_matrix.shape[1]\n",
        "\n",
        "        self.embed = nn.Embedding(num_embedding, num_embedding, padding_idx=0, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False)\n",
        "        layers.append(nn.Conv1d(embedding_dim, 64, kernel_size=3, padding=1))\n",
        "\n",
        "\n",
        "        n_conv_block_64, n_conv_block_128, n_conv_block_256, n_conv_block_512 = 2, 2, 2, 2\n",
        "        n_fc_neurons=2048\n",
        "\n",
        "        layers.append(BasicConvResBlock(input_dim=64, n_filters=64, kernel_size=3, padding=1))\n",
        "        for _ in range(n_conv_block_64-1):\n",
        "            layers.append(BasicConvResBlock(input_dim=64, n_filters=64, kernel_size=3, padding=1))\n",
        "        layers.append(nn.MaxPool1d(kernel_size=3, stride=2, padding=1)) # l = initial length / 2\n",
        "\n",
        "        ds = nn.Sequential(nn.Conv1d(64, 128, kernel_size=1, stride=1, bias=False), nn.BatchNorm1d(128))\n",
        "        layers.append(BasicConvResBlock(input_dim=64, n_filters=128, kernel_size=3, padding=1, downsample=ds))\n",
        "        for _ in range(n_conv_block_128-1):\n",
        "            layers.append(BasicConvResBlock(input_dim=128, n_filters=128, kernel_size=3, padding=1))\n",
        "        layers.append(nn.MaxPool1d(kernel_size=3, stride=2, padding=1)) # l = initial length / 4\n",
        "\n",
        "        ds = nn.Sequential(nn.Conv1d(128, 256, kernel_size=1, stride=1, bias=False), nn.BatchNorm1d(256))\n",
        "        layers.append(BasicConvResBlock(input_dim=128, n_filters=256, kernel_size=3, padding=1, downsample=ds))\n",
        "        for _ in range(n_conv_block_256 - 1):\n",
        "            layers.append(BasicConvResBlock(input_dim=256, n_filters=256, kernel_size=3, padding=1))\n",
        "        layers.append(nn.MaxPool1d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "        ds = nn.Sequential(nn.Conv1d(256, 512, kernel_size=1, stride=1, bias=False), nn.BatchNorm1d(512))\n",
        "        layers.append(BasicConvResBlock(input_dim=256, n_filters=512, kernel_size=3, padding=1, downsample=ds))\n",
        "        for _ in range(n_conv_block_512 - 1):\n",
        "            layers.append(BasicConvResBlock(input_dim=512, n_filters=512, kernel_size=3, padding=1))\n",
        "\n",
        "        layers.append(nn.AdaptiveMaxPool1d(8))\n",
        "        fc_layers.extend([nn.Linear(8*512, n_fc_neurons), nn.ReLU()])\n",
        "\n",
        "        fc_layers.extend([nn.Linear(n_fc_neurons, n_fc_neurons), nn.ReLU()])\n",
        "        fc_layers.extend([nn.Linear(n_fc_neurons, NB_FAMILIES)])\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        self.fc_layers = nn.Sequential(*fc_layers)\n",
        "\n",
        "        self.__init_weights()\n",
        "\n",
        "    def __init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.embed(x)\n",
        "        out = out.transpose(1, 2)\n",
        "\n",
        "        out = self.layers(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = self.fc_layers(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "1rIuTMNhN5rC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ybP67xAE9TN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87c7d2d-28f1-414e-9423-2731aa7f58be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting tokenizer\n",
            "Loading embeddings\n",
            "True\n",
            "Training Model\n",
            "FOLD:0, Epoch: 0, Accuracy Score = 0.516857720836143, Precision Score = 0.3806800471974179, Recall Score = 0.32444074598341166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 1, Accuracy Score = 0.699637559002023, Precision Score = 0.633940114596063, Recall Score = 0.5529808799662123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 2, Accuracy Score = 0.7962744436952124, Precision Score = 0.7575558275811801, Recall Score = 0.6941085262732394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 3, Accuracy Score = 0.8284305461901551, Precision Score = 0.7927169216242822, Recall Score = 0.7402421266269653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 4, Accuracy Score = 0.8174308833445718, Precision Score = 0.7792241592701943, Recall Score = 0.7338993674947555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 5, Accuracy Score = 0.8482383681726231, Precision Score = 0.8074467376415737, Recall Score = 0.7744476756894502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 6, Accuracy Score = 0.8388823331085637, Precision Score = 0.799614384528504, Recall Score = 0.7560973634458482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 7, Accuracy Score = 0.8570886716115981, Precision Score = 0.8166196255918383, Recall Score = 0.7806435070546497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, Epoch: 8, Accuracy Score = 0.8562036412677007, Precision Score = 0.8237741576851157, Recall Score = 0.7833507355611838\n",
            "Fitting tokenizer\n",
            "Loading embeddings\n",
            "True\n",
            "Training Model\n",
            "FOLD:1, Epoch: 0, Accuracy Score = 0.48086648685097777, Precision Score = 0.32410775818146503, Recall Score = 0.2826788210288884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:1, Epoch: 1, Accuracy Score = 0.7418661496965611, Precision Score = 0.6865000487773386, Recall Score = 0.607276337788235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:1, Epoch: 2, Accuracy Score = 0.7891942009440324, Precision Score = 0.7458438102952379, Recall Score = 0.6808345613425635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:1, Epoch: 3, Accuracy Score = 0.8184844908968307, Precision Score = 0.7724877056971368, Recall Score = 0.7213141872141616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:1, Epoch: 4, Accuracy Score = 0.8510198921105866, Precision Score = 0.8168664122497546, Recall Score = 0.774024835691776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:1, Epoch: 5, Accuracy Score = 0.8606287929871881, Precision Score = 0.8296888034131242, Recall Score = 0.7840224639956694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:1, Epoch: 6, Accuracy Score = 0.86083951449764, Precision Score = 0.8353477903586289, Recall Score = 0.7828767471678468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:1, Epoch: 7, Accuracy Score = 0.8714177343223196, Precision Score = 0.8439990965506282, Recall Score = 0.802899131007543\n",
            "FOLD:1, Epoch: 8, Accuracy Score = 0.8916048550236008, Precision Score = 0.858254159863566, Recall Score = 0.8311478415378781\n",
            "FOLD:1, Epoch: 9, Accuracy Score = 0.8927427511800404, Precision Score = 0.8595152544478603, Recall Score = 0.8331426125843615\n",
            "Fitting tokenizer\n",
            "Loading embeddings\n",
            "True\n",
            "Training Model\n",
            "FOLD:2, Epoch: 0, Accuracy Score = 0.5627950101146325, Precision Score = 0.4108494958557723, Recall Score = 0.360979037677768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:2, Epoch: 1, Accuracy Score = 0.7799224544841538, Precision Score = 0.7220646973398166, Recall Score = 0.6671100968245437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:2, Epoch: 2, Accuracy Score = 0.8264497639919083, Precision Score = 0.7859866976945566, Recall Score = 0.7441480305806286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:2, Epoch: 3, Accuracy Score = 0.8112356709372893, Precision Score = 0.7846705472778652, Recall Score = 0.7224147066214869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:2, Epoch: 4, Accuracy Score = 0.8644217801753203, Precision Score = 0.8297676142101126, Recall Score = 0.7966155232736033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:2, Epoch: 5, Accuracy Score = 0.8649275118004046, Precision Score = 0.8304745169986332, Recall Score = 0.799218612459519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:2, Epoch: 6, Accuracy Score = 0.8747471341874579, Precision Score = 0.8470331748032732, Recall Score = 0.809144943877194\n",
            "FOLD:2, Epoch: 7, Accuracy Score = 0.8839345920431557, Precision Score = 0.8579806584868214, Recall Score = 0.821112852379825\n",
            "FOLD:2, Epoch: 8, Accuracy Score = 0.8924477410654079, Precision Score = 0.8594469802899457, Recall Score = 0.8375419613665805\n",
            "FOLD:2, Epoch: 9, Accuracy Score = 0.8870111260957518, Precision Score = 0.8581243716204222, Recall Score = 0.8292108878232847\n",
            "Fitting tokenizer\n",
            "Loading embeddings\n",
            "True\n",
            "Training Model\n",
            "FOLD:3, Epoch: 0, Accuracy Score = 0.5341790289952798, Precision Score = 0.3956970309823497, Recall Score = 0.34266127536756935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:3, Epoch: 1, Accuracy Score = 0.759313890761969, Precision Score = 0.6831661627817218, Recall Score = 0.6378883398051319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:3, Epoch: 2, Accuracy Score = 0.8250168577208361, Precision Score = 0.7750833142335213, Recall Score = 0.7326489830220558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:3, Epoch: 3, Accuracy Score = 0.8431810519217802, Precision Score = 0.7946797588004786, Recall Score = 0.7628025111451059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:3, Epoch: 4, Accuracy Score = 0.8599966284558328, Precision Score = 0.826886724517677, Recall Score = 0.7891578834399822\n",
            "FOLD:3, Epoch: 5, Accuracy Score = 0.8646325016857721, Precision Score = 0.8275176004025688, Recall Score = 0.7995763619776513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:3, Epoch: 6, Accuracy Score = 0.8702376938637896, Precision Score = 0.8378406559676593, Recall Score = 0.8034940031121913\n",
            "FOLD:3, Epoch: 7, Accuracy Score = 0.8858310856372218, Precision Score = 0.8493854289221688, Recall Score = 0.8265309827341949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:3, Epoch: 8, Accuracy Score = 0.8851989211058665, Precision Score = 0.8513899253242248, Recall Score = 0.8265555687210909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:3, Epoch: 9, Accuracy Score = 0.8937542144302091, Precision Score = 0.8661301436565654, Recall Score = 0.834095357623222\n",
            "Fitting tokenizer\n",
            "Loading embeddings\n",
            "True\n",
            "Training Model\n",
            "FOLD:4, Epoch: 0, Accuracy Score = 0.49591200269723534, Precision Score = 0.35217967632489866, Recall Score = 0.32852362493469656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 1, Accuracy Score = 0.725472016183412, Precision Score = 0.6802517345296605, Recall Score = 0.6084176983339175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 2, Accuracy Score = 0.7979180714767363, Precision Score = 0.7521993399879423, Recall Score = 0.7014878968471556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 3, Accuracy Score = 0.8256911665542819, Precision Score = 0.7919235645843372, Recall Score = 0.739892871807074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 4, Accuracy Score = 0.8406945380984491, Precision Score = 0.8066494181789506, Recall Score = 0.7565959231185685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 5, Accuracy Score = 0.8516099123398516, Precision Score = 0.825632460862489, Recall Score = 0.7747660944294829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 6, Accuracy Score = 0.8751264329062711, Precision Score = 0.8469977381393384, Recall Score = 0.8050646605022543\n",
            "FOLD:4, Epoch: 7, Accuracy Score = 0.8335300067430883, Precision Score = 0.8200003853826744, Recall Score = 0.7470035824888012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 8, Accuracy Score = 0.8815323668240054, Precision Score = 0.8575186839063172, Recall Score = 0.8173681085013211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:4, Epoch: 9, Accuracy Score = 0.8787508428860418, Precision Score = 0.8556219307614149, Recall Score = 0.8100845748559438\n",
            "Average accuracy : 0.8816925151719488\n",
            "Average precision : 0.8526331716342757\n",
            "Average recall : 0.8179768336895993\n"
          ]
        }
      ],
      "source": [
        "# train.py\n",
        "import io\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# yes, we use tensorflow\n",
        "# but not for training the model!\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "\n",
        "def train(data_loader, model, optimizer, device):\n",
        "     \"\"\"\n",
        "    This is the main training function that trains model\n",
        "     for one epoch\n",
        "     :param data_loader: this is the torch dataloader\n",
        "     :param model: model (lstm model)\n",
        "     :param optimizer: torch optimizer, e.g. adam, sgd, etc.\n",
        "     :param device: this can be \"cuda\" or \"cpu\"\n",
        "     \"\"\"\n",
        "\n",
        "     # set model to training mode\n",
        "     model.train()\n",
        "     # go through batches of data in data loader\n",
        "     for data in data_loader:\n",
        "         # fetch review and target from the dict\n",
        "         reviews = data[\"review\"]\n",
        "         targets = data[\"target\"]\n",
        "         # move the data to device that we want to use\n",
        "         reviews = reviews.to(device, dtype=torch.long)\n",
        "         targets = targets.to(device, dtype=torch.long)\n",
        "         # clear the gradients\n",
        "         optimizer.zero_grad()\n",
        "         # make predictions from the model\n",
        "         predictions = model(reviews)\n",
        "\n",
        "         # calculate the loss\n",
        "         loss = nn.CrossEntropyLoss()(\n",
        "         predictions,\n",
        "         targets\n",
        "         )\n",
        "         # compute gradient of loss w.r.t.\n",
        "         # all parameters of the model that are trainable\n",
        "         loss.backward()\n",
        "         # single optimization step\n",
        "         optimizer.step()\n",
        "\n",
        "def evaluate(data_loader, model, device):\n",
        "     # initialize empty lists to store predictions\n",
        "     # and targets\n",
        "     final_predictions = []\n",
        "     final_targets = []\n",
        "     # put the model in eval mode\n",
        "     model.eval()\n",
        "     # disable gradient calculation\n",
        "     with torch.no_grad():\n",
        "         for data in data_loader:\n",
        "             reviews = data[\"review\"]\n",
        "             targets = data[\"target\"]\n",
        "             reviews = reviews.to(device, dtype=torch.long)\n",
        "             targets = targets.to(device, dtype=torch.float)\n",
        "             # make predictions\n",
        "             predictions = model(reviews)\n",
        "             # move predictions and targets to list\n",
        "             # we need to move predictions and targets to cpu too\n",
        "             predictions = predictions.cpu().numpy().tolist()\n",
        "             targets = data[\"target\"].cpu().numpy().tolist()\n",
        "             final_predictions.extend(predictions)\n",
        "             final_targets.extend(targets)\n",
        "     # return final predictions and targets\n",
        "     return final_predictions, final_targets\n",
        "\n",
        "def create_embedding_matrix(word_index, embedding_dict):\n",
        "    \"\"\"\n",
        "    This function creates the embedding matrix.\n",
        "    :param word_index: a dictionary with word:index_value\n",
        "    :param embedding_dict: a dictionary with word:embedding_vector\n",
        "    :return: a numpy array with embedding vectors for all known words\n",
        "    \"\"\"\n",
        "    # initialize matrix with zeros\n",
        "    embedding_matrix = []\n",
        "    # loop over all the words\n",
        "    for word, i in word_index.items():\n",
        "        # if word is found in pre-trained embeddings,\n",
        "        # update the matrix. if the word is not found,\n",
        "        # the vector is zeros!\n",
        "        if word in embedding_dict:\n",
        "            embedding_matrix.append(embedding_dict[word])\n",
        "        # return embedding matrix\n",
        "    return np.array(embedding_matrix)\n",
        "\n",
        "\n",
        "def tokenizing(df, char_index_dict):\n",
        "    final_string = []\n",
        "    for sentence in df['sequence']:\n",
        "        sequence = []\n",
        "        for word in sentence:\n",
        "            x = char_index_dict[word]\n",
        "            sequence.append(str(x))\n",
        "        final_string.append(sequence)\n",
        "    df['clean_seq'] = final_string\n",
        "\n",
        "    return df\n",
        "\n",
        "def one_hot():\n",
        "    nb_classes = len(CHAR_INDEX_DICT)\n",
        "    one_hot_embedding_mat = np.eye(nb_classes)\n",
        "    one_hot_embedding = {}\n",
        "    for key, value in enumerate(CHAR_INDEX_DICT):\n",
        "        one_hot_embedding[value] = one_hot_embedding_mat[key]\n",
        "    return one_hot_embedding\n",
        "\n",
        "def run(df, fold):\n",
        "    \"\"\"\n",
        "    Run training and validation for a given fold\n",
        "    and dataset\n",
        "    :param df: pandas dataframe with kfold column\n",
        "    :param fold: current fold, int\n",
        "    \"\"\"\n",
        "    # fetch training dataframe\n",
        "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "    # fetch validation dataframe\n",
        "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "    print(\"Fitting tokenizer\")\n",
        "    # convert training data to sequences\n",
        "    # for example : \"bad movie\" gets converted to\n",
        "    # [24, 27] where 24 is the index for bad and 27 is the\n",
        "    # index for movie\n",
        "    xtrain = list(tokenizing(train_df,CHAR_INDEX_DICT)['clean_seq'])\n",
        "    # similarly convert validation data to\n",
        "    # sequences\n",
        "    xtest = list(tokenizing(valid_df,CHAR_INDEX_DICT)['clean_seq'])\n",
        "    # zero pad the training sequences given the maximum length\n",
        "    # this padding is done on left hand side\n",
        "    # if sequence is > MAX_LEN, it is truncated on left hand side too\n",
        "    xtrain = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        xtrain, maxlen=MAX_LEN\n",
        "    )\n",
        "    # zero pad the validation sequences\n",
        "    xtest = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        xtest, maxlen=MAX_LEN\n",
        "    )\n",
        "    # initialize dataset class for training\n",
        "    train_dataset = PFAMDataset(\n",
        "        reviews=xtrain,\n",
        "        targets=train_df.family_id.values\n",
        "    )\n",
        "    # create torch dataloader for training\n",
        "    # torch dataloader loads the data using dataset\n",
        "    # class in batches specified by batch size\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TRAIN_BATCH_SIZE,\n",
        "        num_workers=2\n",
        "    )\n",
        "    # initialize dataset class for validation\n",
        "    valid_dataset = PFAMDataset(\n",
        "        reviews=xtest,\n",
        "        targets=valid_df.family_id.values\n",
        "    )\n",
        "\n",
        "    # create torch dataloader for validation\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=VALID_BATCH_SIZE,\n",
        "        num_workers=1\n",
        "    )\n",
        "    print(\"Loading embeddings\")\n",
        "    # load embeddings as shown previously\n",
        "    embedding_dict = one_hot()\n",
        "    embedding_matrix = create_embedding_matrix(\n",
        "        CHAR_INDEX_DICT, embedding_dict\n",
        "    )\n",
        "    # create torch device, since we use gpu, we are using cuda\n",
        "    print(torch.cuda.is_available())\n",
        "    device = torch.device(\"cuda\")\n",
        "    # fetch our model\n",
        "    # model = LSTM(embedding_matrix)\n",
        "    model = VDCNN(embedding_matrix)\n",
        "    # send model to device\n",
        "    model.to(device)\n",
        "\n",
        "    # initialize Adam optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    print(\"Training Model\")\n",
        "    # set best accuracy to zero\n",
        "    best_accuracy = 0\n",
        "    # set early stopping counter to zero\n",
        "    early_stopping_counter = 0\n",
        "    # train and validate for all epochs\n",
        "    for epoch in range(EPOCHS):\n",
        "        # train one epoch\n",
        "        train(train_data_loader, model, optimizer, device)\n",
        "        # validate\n",
        "        outputs, targets = evaluate(\n",
        "            valid_data_loader, model, device\n",
        "        )\n",
        "        # use threshold of 0.5\n",
        "        # please note we are using linear layer and no sigmoid\n",
        "        # you should do this 0.5 threshold after sigmoid\n",
        "        outputs = np.array(outputs) \n",
        "        # calculate accuracy\n",
        "        accuracy = metrics.accuracy_score(targets, np.argmax(outputs,axis=1))\n",
        "        precision = metrics.precision_score(targets, np.argmax(outputs,axis=1),average='macro')\n",
        "        recall = metrics.recall_score(targets, np.argmax(outputs,axis=1),average='macro')\n",
        "\n",
        "        print(\n",
        "            f\"FOLD:{fold}, Epoch: {epoch}, Accuracy Score = {accuracy}, Precision Score = {precision}, Recall Score = {recall}\"\n",
        "        )\n",
        "        # simple early stopping\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "        if early_stopping_counter > 2:\n",
        "            break\n",
        "    return accuracy,precision, recall\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "     # load data\n",
        "     df = pd.read_csv(\"/content/pfam_736_folds.csv\")\n",
        "     # train for all folds\n",
        "     accuracy_0,precision_0, recall_0 = run(df, fold=0)\n",
        "     accuracy_1,precision_1, recall_1 = run(df, fold=1)\n",
        "     accuracy_2,precision_2, recall_2 = run(df, fold=2)\n",
        "     accuracy_3,precision_3, recall_3 = run(df, fold=3)\n",
        "     accuracy_4,precision_4, recall_4 = run(df, fold=4)\n",
        "     print('Average accuracy : ' + str(np.mean(np.array([accuracy_0,accuracy_1,accuracy_2,accuracy_3,accuracy_4]))))\n",
        "     print('Average precision : ' + str(np.mean(np.array([precision_0,precision_1,precision_2,precision_3,precision_4]))))\n",
        "     print('Average recall : ' + str(np.mean(np.array([recall_0,recall_1,recall_2,recall_3,recall_4]))))\n"
      ]
    }
  ]
}